{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LinearFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, weights):\n",
    "        output = input.mm(weights)\n",
    "        ctx.save_for_backward(input, weights)\n",
    "        return output\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_outputs):\n",
    "        input, weights = ctx.saved_tensors\n",
    "        grad_weights = grad_outputs.t().mm(input).t()\n",
    "        grad_input = grad_outputs.mm(weights.t())\n",
    "        return grad_input, grad_weights\n",
    "\n",
    "class LinearLayer(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearLayer, self).__init__()\n",
    "        self.weights = torch.nn.Parameter(torch.rand((input_dim, output_dim)))\n",
    "        self.layer = LinearFunction.apply\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x, self.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.7965],\n",
      "        [2.2336],\n",
      "        [1.9711],\n",
      "        [2.8940],\n",
      "        [1.7923],\n",
      "        [1.7834],\n",
      "        [1.8158],\n",
      "        [2.2971],\n",
      "        [1.6177],\n",
      "        [2.0345]])\n",
      "tensor([[0.3557, 0.2679, 0.4707, 0.2759, 0.2922, 0.2862, 0.4475, 0.0061, 0.0175,\n",
      "         0.3846],\n",
      "        [0.5588, 0.4208, 0.7394, 0.4335, 0.4590, 0.4496, 0.7029, 0.0096, 0.0274,\n",
      "         0.6042],\n",
      "        [0.2565, 0.1932, 0.3394, 0.1990, 0.2107, 0.2064, 0.3227, 0.0044, 0.0126,\n",
      "         0.2774],\n",
      "        [0.3264, 0.2458, 0.4319, 0.2532, 0.2681, 0.2626, 0.4106, 0.0056, 0.0160,\n",
      "         0.3530],\n",
      "        [0.4176, 0.3145, 0.5526, 0.3239, 0.3430, 0.3360, 0.5253, 0.0071, 0.0205,\n",
      "         0.4515],\n",
      "        [0.3182, 0.2397, 0.4211, 0.2469, 0.2614, 0.2560, 0.4003, 0.0054, 0.0156,\n",
      "         0.3441],\n",
      "        [0.3219, 0.2424, 0.4259, 0.2497, 0.2644, 0.2589, 0.4049, 0.0055, 0.0158,\n",
      "         0.3480],\n",
      "        [0.2949, 0.2221, 0.3902, 0.2288, 0.2422, 0.2373, 0.3710, 0.0050, 0.0145,\n",
      "         0.3189]])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((8,10),requires_grad=True)\n",
    "ll = LinearLayer(10, 1)\n",
    "out = ll(x)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "loss = loss_fn(out, torch.rand(out.shape))\n",
    "loss.backward()\n",
    "print(ll.weights.grad)\n",
    "print(x.grad)\n",
    "print(x.is_leaf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('plantpart')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "788ce38e033d031edf7362c4d6e542c9e2351109696c126a1d0cf4142b964d4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
